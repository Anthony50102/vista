{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f74dbb-3e49-4372-913d-5214d716a02a",
   "metadata": {},
   "source": [
    "## A FNO network to learn the output\n",
    "### Ideas on how to do this\n",
    "- Naive guess: Freeze FNO use simple conv net to learn output\n",
    "- More apples to apples: Freeze FNO use another FNO for output?\n",
    "- Maybe more advanced training strategies? Freeze one, freeze the other over and over then learn both?\n",
    "\n",
    "### This notebooks implementation\n",
    "- Process data to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fdfd276-3b3b-4ccc-a2a6-d28c41b90ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUsing Device: cuda\n",
      "\u001b[1mShowing animations: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import h5py\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "from IPython.display import HTML, display\n",
    "from neuralop.models import FNO\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from neuralop.data.datasets import load_darcy_flow_small\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "show_animations = True\n",
    "data_truncation = .5\n",
    "\n",
    "plt.rcParams['animation.embed_limit'] = 500\n",
    "\n",
    "print(f\"\\033[1mUsing Device: {device}\")\n",
    "print(f\"\\033[1mShowing animations: {show_animations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "649b5d4b-a071-42d6-9bdb-ee0b57742f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and save as .np\n",
    "\n",
    "data_dir = \"/work/10407/anthony50102/frontera/data/hw2d_sim/t600_d256x256_raw/\"\n",
    "\n",
    "train_files = [\"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250315142044_11702_0.h5\",\n",
    "               \"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250315142045_4677_2.h5\"]\n",
    "test_files = [\"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250316215751_19984_3.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01ab03ad-4b6c-4f25-ade2-cf8e8adc33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_derived(density, potential, gamma_n, gamma_c):\n",
    "    derived_data = np.concatenate(\n",
    "        (np.expand_dims(gamma_n, 1), np.expand_dims(gamma_c, 1)),\n",
    "        axis=1)\n",
    "    derived_mask = np.broadcast_to(derived_data[:, :, None, None], (derived_data.shape[0], derived_data.shape[1], 256, 256))\n",
    "    data = np.concatenate(\n",
    "        (np.expand_dims(density, 1),\n",
    "         np.expand_dims(potential, 1),\n",
    "         derived_mask),\n",
    "        axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "processed_train_files = []\n",
    "\n",
    "for file in train_files:\n",
    "    save_name = \"train_\" + \"\".join(file.split(\".\")[:-1]) + \"_derived.npz\"\n",
    "    if os.path.exists(save_name):\n",
    "        print(f\"File already processed: {save_name}\")\n",
    "        continue\n",
    "    else:\n",
    "        with h5py.File(data_dir + file, 'r') as f:\n",
    "            end_index = int(f['density'].shape[0] * data_truncation)\n",
    "            density = f['density'][:end_index]\n",
    "            potential = f['phi'][:end_index]\n",
    "            gamma_n = f['gamma_n'][:end_index]\n",
    "            gamma_c = f['gamma_c'][:end_index]\n",
    "            data = process_derived(density, potential, gamma_n, gamma_c)\n",
    "    \n",
    "            processed_train_files.append(save_name)\n",
    "    \n",
    "            np.savez(\n",
    "                save_name,\n",
    "                data=data,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "945f6af2-7ba7-4018-9e1f-a345f7f0ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8000, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class TrajDataset(Dataset):\n",
    "    # TODO: Look into LRU or memory mapping too speed this up\n",
    "    def __init__(self, data_path,\n",
    "                 train_split=0.8,\n",
    "                 val_split=0.5,\n",
    "                 mode='train'):\n",
    "        # Get all .npz files with full paths\n",
    "        self.data_path = data_path\n",
    "        all_files = [os.path.join(data_path, f) \n",
    "                     for f in os.listdir(data_path) \n",
    "                     if f.endswith(\".npz\")]\n",
    "\n",
    "        self.num_files = len(all_files)\n",
    "\n",
    "        # Split files\n",
    "        train_end = int(self.num_files * train_split)\n",
    "        val_end = train_end + int((self.num_files - train_end) * val_split)\n",
    "\n",
    "        self.train_files = all_files[:train_end]\n",
    "        self.val_files = all_files[train_end:val_end]\n",
    "        self.test_files = all_files[val_end:]\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.avail_files = self.train_files\n",
    "        elif mode == 'val':\n",
    "            self.avail_files = self.val_files\n",
    "        elif mode == 'test':\n",
    "            self.avail_files = self.test_files\n",
    "        else:\n",
    "            raise ValueError(f\"mode must be 'train', 'val', or 'test', got {mode}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.avail_files)  # Fixed: should be length of available files, not total\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.avail_files[idx])[\"data\"]\n",
    "        return {'data': data}\n",
    "\n",
    "def create_traj_loader(data_path, batch_size=1, num_workers=1):\n",
    "    dataset = TrajDataset(data_path)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=num_workers)\n",
    "    return loader\n",
    "\n",
    "# Usage example:\n",
    "data_path = processed_train_files[0]\n",
    "\n",
    "traj_loader = create_traj_loader(\".\")\n",
    "\n",
    "# Test the loader\n",
    "for traj in traj_loader:\n",
    "    print(traj['data'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4eb7b3-5f54-450a-9c20-4df2eef5e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = FNO(\n",
    "    n_modes=(64, 64),\n",
    "    in_channels=2,\n",
    "    out_channels=2,\n",
    "    hidden_channels=512,\n",
    "    # projection_channel_ratio=2,\n",
    ")\n",
    "output_model = output_model.to(device)\n",
    "\n",
    "# Count and display the number of parameters\n",
    "n_params = count_model_params(output_model)\n",
    "print(f\"\\nOur output model has {n_params} parameters.\")\n",
    "\n",
    "# Load the state prediction model\n",
    "# state_model = load(\"state_model.pth\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50e449-11da-4ff1-a498-a3277278176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(output_model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "l2loss = LpLoss(d=2, p=2)  # L2 loss for function values\n",
    "h1loss = H1Loss(d=2)  # H1 loss includes gradient information\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses = {\"h1\": h1loss, \"l2\": l2loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc2dfb-9096-4ca6-a3de-e73c9e5a4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "# Simple hyperparameters\n",
    "max_epochs = 1000\n",
    "max_rollout_length = 90\n",
    "stabilization_epochs = 10  # Wait this long for stability\n",
    "stability_window = 10  # Check last N epochs for stability\n",
    "max_loss_variance = 0.001  # Loss variance must be below this\n",
    "clip_norm = 1.0\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Training state\n",
    "current_rollout = 1\n",
    "epochs_since_increase = 0\n",
    "recent_losses = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_loss = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in traj_loader:\n",
    "        traj = batch['data'].to(device).float()\n",
    "        batch_size, traj_len, c, h, w = traj.shape\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Always do some single-step training\n",
    "        for _ in range(5):\n",
    "            idx = random.randint(0, traj_len - 2)\n",
    "            state_pred = state_model(traj[:, idx, :2])\n",
    "            derived_pred = output_model(state_pred)  # b, c , h, w\n",
    "            loss = nn.functional.mse_loss(derived_pred, traj[:, idx + 1, 2:])\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Rollout training\n",
    "        if current_rollout > 1:\n",
    "            start = random.randint(0, traj_len - current_rollout - 1)\n",
    "            state = traj[:, start, :2].clone()  # Start with actual state channels\n",
    "\n",
    "            for step in range(current_rollout):\n",
    "                state_pred = state_model(state)  # Predict next state\n",
    "                derived_pred = output_model(state_pred)  # Compute derived quantities\n",
    "\n",
    "                target = traj[:, start + step + 1, 2:]\n",
    "                loss = nn.functional.mse_loss(derived_pred, target)\n",
    "                loss.backward()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Update state for next iteration (autoregressive)\n",
    "                state = state_pred.detach()  # ✓ Fixed: use state_pred\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(output_model.parameters(), max_norm=clip_norm)\n",
    "        optimizer.step()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / (n_batches * (5 + max(1, current_rollout)))\n",
    "    epochs_since_increase += 1\n",
    "\n",
    "    # Track recent losses\n",
    "    recent_losses.append(avg_loss)\n",
    "    if len(recent_losses) > stability_window:\n",
    "        recent_losses.pop(0)\n",
    "\n",
    "    # Check if loss is stable (low variance)\n",
    "    is_stable = False\n",
    "    if len(recent_losses) >= stability_window:\n",
    "        mean_loss = sum(recent_losses) / len(recent_losses)\n",
    "        variance = sum((l - mean_loss) ** 2 for l in recent_losses) / len(recent_losses)\n",
    "        is_stable = variance < max_loss_variance\n",
    "\n",
    "    # Increase rollout if stable and waited long enough\n",
    "    should_increase = (\n",
    "        epochs_since_increase >= stabilization_epochs and\n",
    "        is_stable and\n",
    "        current_rollout < max_rollout_length\n",
    "    )\n",
    "\n",
    "    if should_increase:\n",
    "        current_rollout += 1\n",
    "        epochs_since_increase = 0\n",
    "        recent_losses = []  # Reset after increase\n",
    "        print(f\"  → Increasing rollout to {current_rollout}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Rollout: {current_rollout}, \"\n",
    "          f\"Stable: {is_stable}, Epochs: {epochs_since_increase}\")\n",
    "\n",
    "    if current_rollout >= max_rollout_length:\n",
    "        print(f\"Reached max rollout of {max_rollout_length}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717735c6-6e10-4519-b81e-5d215dde3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(state_model, data, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Autoregressive rollout:\n",
    "    - data: numpy array of shape (T, C, X, Y)\n",
    "    - model: forward prediction operator\n",
    "    - returns: reconstruction of full trajectory\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    T, C, X, Y = data.shape\n",
    "\n",
    "    # Storage for reconstruction\n",
    "    recon = np.zeros_like(data)\n",
    "\n",
    "    # Initial condition (t=0)\n",
    "    current = torch.from_numpy(data[0]).float().to(device)\n",
    "    recon[0] = data[0]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        # Model expects batch dimension\n",
    "        inp = current.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred = model(inp)  # output shape: (1, C, X, Y)\n",
    "        pred_np = pred.squeeze(0).cpu().numpy()\n",
    "        recon[t] = pred_np\n",
    "        # Feed output back in\n",
    "        current = pred.squeeze(0)\n",
    "\n",
    "    return recon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
