{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f74dbb-3e49-4372-913d-5214d716a02a",
   "metadata": {},
   "source": [
    "## Conv Output Learning: State → Derived Quantities\n",
    "\n",
    "### Architecture Overview\n",
    "This notebook trains a **CNN-based model** to map **state(t) → derived(t)**, where:\n",
    "- **State**: (density, potential) - shape (2, H, W)\n",
    "- **Derived**: (gamma_n, gamma_c) - scalar values\n",
    "\n",
    "### Comparison with FNO Output Learning\n",
    "- **FNO**: Learns in frequency domain, good for smooth/global patterns\n",
    "- **CNN**: Learns local spatial patterns, potentially faster and more parameter-efficient\n",
    "\n",
    "### Combined Inference Pipeline\n",
    "1. **State Model** (from `fno_test.ipynb`): state(t) → state(t+1) (autoregressive)\n",
    "2. **Output Model** (this notebook): state(t) → derived(t) (CNN-based direct mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18388b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "from IPython.display import HTML, display\n",
    "from neuralop.models import FNO\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import (\n",
    "    load_h5_data, process_state_data, process_derived_data,\n",
    "    StateDerivedDataset, TrajectoryWithDerivedDataset,\n",
    "    save_model, load_model,\n",
    "    train_epoch_direct, validate_direct,\n",
    "    rollout_combined, compute_mse_over_time, print_summary\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "show_animations = True\n",
    "data_truncation = 0.5\n",
    "\n",
    "plt.rcParams['animation.embed_limit'] = 500\n",
    "\n",
    "print(f\"\\033[1mUsing Device: {device}\")\n",
    "print(f\"\\033[1mShowing animations: {show_animations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fafb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "data_dir = \"/work/10407/anthony50102/frontera/data/hw2d_sim/t600_d256x256_raw/\"\n",
    "\n",
    "train_files = [\"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250315142044_11702_0.h5\",\n",
    "               \"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250315142045_4677_2.h5\"]\n",
    "test_files = [\"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250316215751_19984_3.h5\"]\n",
    "\n",
    "# Model checkpoints\n",
    "STATE_MODEL_NAME = \"state_model\"\n",
    "CNN_OUTPUT_MODEL_NAME = \"derived_cnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ddfa0",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9416ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save data with derived quantities\n",
    "import os\n",
    "\n",
    "processed_files = []\n",
    "\n",
    "for file in train_files:\n",
    "    save_name = \"output_train_\" + \"\".join(file.split(\".\")[:-1]) + \".npz\"\n",
    "    \n",
    "    if os.path.exists(save_name):\n",
    "        print(f\"File already processed: {save_name}\")\n",
    "        processed_files.append(save_name)\n",
    "        continue\n",
    "    \n",
    "    data = load_h5_data(data_dir + file, truncation=data_truncation)\n",
    "    state = process_state_data(data['density'], data['potential'])\n",
    "    derived = process_derived_data(data['gamma_n'], data['gamma_c'])\n",
    "    \n",
    "    np.savez(save_name, state=state, derived=derived)\n",
    "    processed_files.append(save_name)\n",
    "    print(f\"Saved: {save_name}\")\n",
    "\n",
    "print(f\"\\nProcessed {len(processed_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d072f08",
   "metadata": {},
   "source": [
    "### Dataset and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders using shared dataset classes\n",
    "data_path = processed_files[0]\n",
    "\n",
    "train_dataset = StateDerivedDataset(data_path, mode='train')\n",
    "val_dataset = StateDerivedDataset(data_path, mode='val')\n",
    "test_dataset = StateDerivedDataset(data_path, mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# Trajectory loader for rollout training\n",
    "traj_loader = DataLoader(TrajectoryWithDerivedDataset(\".\", mode='train'), batch_size=1, shuffle=True)\n",
    "\n",
    "# Test\n",
    "for batch in train_loader:\n",
    "    print(f\"State shape: {batch['state'].shape}\")    # (batch, 2, H, W)\n",
    "    print(f\"Derived shape: {batch['derived'].shape}\")  # (batch, 2)\n",
    "    break\n",
    "\n",
    "print(f\"\\nTrain: {len(train_loader.dataset)} | Val: {len(val_loader.dataset)} | Test: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0d518",
   "metadata": {},
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9630b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained state model (architecture only - loaded later during evaluation)\n",
    "print(f\"State model will be loaded from: {STATE_MODEL_NAME}_latest.pt\")\n",
    "print(\"Train state model in fno_test.ipynb first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== CNN-based Output Model ==============\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with two conv layers and skip connection.\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    \"\"\"CNN encoder: progressively downsample then pool to scalar.\"\"\"\n",
    "    def __init__(self, in_channels=2, hidden_channels=64, num_res_blocks=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 256 → 128 → 64 → 32 → 16 → 8\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        channels = hidden_channels\n",
    "        for _ in range(5):\n",
    "            out_channels = min(channels * 2, 512)\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                *[ResidualBlock(out_channels) for _ in range(num_res_blocks)]\n",
    "            )\n",
    "            self.down_blocks.append(block)\n",
    "            channels = out_channels\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, 128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        for block in self.down_blocks:\n",
    "            x = block(x)\n",
    "        x = self.global_pool(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class LightweightConvNet(nn.Module):\n",
    "    \"\"\"Lighter CNN: fewer params, faster training.\"\"\"\n",
    "    def __init__(self, in_channels=2, base_channels=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, 4, 2, 1), nn.BatchNorm2d(base_channels), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels*2, 4, 2, 1), nn.BatchNorm2d(base_channels*2), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 4, 2, 1), nn.BatchNorm2d(base_channels*4), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*4, base_channels*8, 4, 2, 1), nn.BatchNorm2d(base_channels*8), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*8, base_channels*8, 4, 2, 1), nn.BatchNorm2d(base_channels*8), nn.ReLU(),\n",
    "        )\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(base_channels*8, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(self.global_pool(self.features(x)).flatten(1))\n",
    "\n",
    "\n",
    "# Choose model\n",
    "USE_LIGHTWEIGHT = False\n",
    "\n",
    "if USE_LIGHTWEIGHT:\n",
    "    conv_output_model = LightweightConvNet(in_channels=2, base_channels=32).to(device)\n",
    "    print(\"Using LightweightConvNet\")\n",
    "else:\n",
    "    conv_output_model = ConvEncoder(in_channels=2, hidden_channels=64, num_res_blocks=2).to(device)\n",
    "    print(\"Using ConvEncoder\")\n",
    "\n",
    "n_params = sum(p.numel() for p in conv_output_model.parameters())\n",
    "print(f\"CNN output model: {n_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd88e65",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_with_rollout(derived_model, state_model, traj_loader, optimizer, device, rollout_len, num_epochs):\n",
    "    \"\"\"Train derived model on state model rollout predictions.\"\"\"\n",
    "    derived_model.train()\n",
    "    state_model.eval()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, n_batches = 0, 0\n",
    "        \n",
    "        for batch in traj_loader:\n",
    "            state_traj = batch['state'].to(device)      # (1, T, 2, H, W)\n",
    "            derived_traj = batch['derived'].to(device)  # (1, T, 2)\n",
    "            \n",
    "            _, T, c, h, w = state_traj.shape\n",
    "            max_start = T - rollout_len - 1\n",
    "            if max_start < 0:\n",
    "                continue\n",
    "            \n",
    "            start = random.randint(0, max_start)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            state = state_traj[:, start]\n",
    "            loss = 0\n",
    "            \n",
    "            for step in range(rollout_len):\n",
    "                loss += F.mse_loss(derived_model(state), derived_traj[:, start + step])\n",
    "                with torch.no_grad():\n",
    "                    state = state_model(state)\n",
    "            \n",
    "            (loss / rollout_len).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(derived_model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() / rollout_len\n",
    "            n_batches += 1\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"[Rollout={rollout_len}] Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/max(n_batches,1):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Phase 1: Direct Mapping ==============\n",
    "print(\"=\" * 50)\n",
    "print(\"Phase 1: Direct state → derived mapping (CNN)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "optimizer = AdamW(conv_output_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch_direct(conv_output_model, train_loader, optimizer, device)\n",
    "    val_loss = validate_direct(conv_output_model, val_loader, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_model(conv_output_model, CNN_OUTPUT_MODEL_NAME, metadata={'epoch': epoch, 'val_loss': val_loss})\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train: {train_loss:.6f} | Val: {val_loss:.6f}\")\n",
    "\n",
    "# Load best\n",
    "load_model(conv_output_model, CNN_OUTPUT_MODEL_NAME)\n",
    "print(f\"\\nBest validation loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66bc345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(train_losses, label='Train')\n",
    "ax.plot(val_losses, label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE Loss')\n",
    "ax.set_title('CNN Output Model: Training Curves')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21945292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Rollout training (uncomment after training state model)\n",
    "# print(\"\\n\" + \"=\" * 50)\n",
    "# print(\"Phase 2: Rollout fine-tuning\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# state_model = FNO(n_modes=(64, 64), in_channels=2, out_channels=2, hidden_channels=512).to(device)\n",
    "# load_model(state_model, STATE_MODEL_NAME)\n",
    "# state_model.eval()\n",
    "\n",
    "# optimizer = AdamW(conv_output_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "# for rollout_len in [5, 10, 20]:\n",
    "#     train_with_rollout(conv_output_model, state_model, traj_loader, optimizer, device, rollout_len, num_epochs=15)\n",
    "# save_model(conv_output_model, CNN_OUTPUT_MODEL_NAME, metadata={'phase': 'rollout'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c9a0c",
   "metadata": {},
   "source": [
    "### Combined Rollout and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe32810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load state model for rollout evaluation\n",
    "state_model = FNO(n_modes=(64, 64), in_channels=2, out_channels=2, hidden_channels=512).to(device)\n",
    "try:\n",
    "    load_model(state_model, STATE_MODEL_NAME)\n",
    "    state_model.eval()\n",
    "except FileNotFoundError:\n",
    "    print(\"State model not found - using untrained model for demo\")\n",
    "\n",
    "# Load test data\n",
    "test_data = np.load(data_path)\n",
    "test_start = int(len(test_data['state']) * 0.9)\n",
    "test_state = test_data['state'][test_start:]\n",
    "test_derived = test_data['derived'][test_start:]\n",
    "\n",
    "print(f\"Test state shape: {test_state.shape}\")\n",
    "print(f\"Test derived shape: {test_derived.shape}\")\n",
    "\n",
    "# Run combined rollout\n",
    "num_steps = min(len(test_state), 200)\n",
    "state_recon, derived_recon = rollout_combined(\n",
    "    state_model, conv_output_model, test_state[0], num_steps, device\n",
    ")\n",
    "print(f\"Rollout complete: {state_recon.shape}, {derived_recon.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Gamma_n comparison\n",
    "axes[0, 0].plot(test_derived[:num_steps, 0], 'b-', label='Ground Truth', alpha=0.8)\n",
    "axes[0, 0].plot(derived_recon[:, 0], 'r--', label='CNN Predicted', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Timestep')\n",
    "axes[0, 0].set_ylabel('gamma_n')\n",
    "axes[0, 0].set_title('Gamma_n: Ground Truth vs Predicted')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gamma_c comparison\n",
    "axes[0, 1].plot(test_derived[:num_steps, 1], 'b-', label='Ground Truth', alpha=0.8)\n",
    "axes[0, 1].plot(derived_recon[:, 1], 'r--', label='CNN Predicted', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Timestep')\n",
    "axes[0, 1].set_ylabel('gamma_c')\n",
    "axes[0, 1].set_title('Gamma_c: Ground Truth vs Predicted')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Derived quantity errors\n",
    "gamma_n_mse = compute_mse_over_time(test_derived[:num_steps, 0:1], derived_recon[:, 0:1])\n",
    "gamma_c_mse = compute_mse_over_time(test_derived[:num_steps, 1:2], derived_recon[:, 1:2])\n",
    "axes[1, 0].plot(gamma_n_mse, label='gamma_n')\n",
    "axes[1, 0].plot(gamma_c_mse, label='gamma_c')\n",
    "axes[1, 0].set_xlabel('Timestep')\n",
    "axes[1, 0].set_ylabel('MSE')\n",
    "axes[1, 0].set_title('Derived Quantity MSE Over Time')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# State MSE\n",
    "state_mse = compute_mse_over_time(test_state[:num_steps], state_recon)\n",
    "axes[1, 1].plot(state_mse)\n",
    "axes[1, 1].set_xlabel('Timestep')\n",
    "axes[1, 1].set_ylabel('MSE')\n",
    "axes[1, 1].set_title('State Prediction MSE')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CNN Model Summary\")\n",
    "print(\"=\" * 50)\n",
    "print_summary(\"State MSE\", state_mse)\n",
    "print_summary(\"Gamma_n MSE\", gamma_n_mse)\n",
    "print_summary(\"Gamma_c MSE\", gamma_c_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation\n",
    "if show_animations:\n",
    "    print(\"\\033[1mState reconstruction animation (CNN)\")\n",
    "    \n",
    "    step = 5\n",
    "    gt = test_state[:num_steps:step]\n",
    "    pred = state_recon[::step]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    vmin, vmax = gt[:, 0].min(), gt[:, 0].max()\n",
    "    \n",
    "    img1 = axes[0].imshow(gt[0, 0], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "    img2 = axes[1].imshow(pred[0, 0], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[1].set_title(\"CNN Surrogate\")\n",
    "    plt.colorbar(img1, ax=axes[0], fraction=0.046)\n",
    "    plt.colorbar(img2, ax=axes[1], fraction=0.046)\n",
    "    \n",
    "    def animate(frame):\n",
    "        img1.set_data(gt[frame, 0])\n",
    "        img2.set_data(pred[frame, 0])\n",
    "        return [img1, img2]\n",
    "    \n",
    "    animation = anim.FuncAnimation(fig, animate, frames=len(gt), interval=50, blit=True)\n",
    "    display(HTML(animation.to_jshtml()))\n",
    "else:\n",
    "    print(\"Animations disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f73433",
   "metadata": {},
   "source": [
    "### Model Comparison: CNN vs FNO\n",
    "Load both models and compare their performance on the same test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Model Comparison: CNN vs FNO ==============\n",
    "# Run after training both notebooks\n",
    "\n",
    "def compare_models(cnn_model, fno_model, loader, device):\n",
    "    \"\"\"Compare CNN and FNO on ground truth states.\"\"\"\n",
    "    cnn_model.eval()\n",
    "    fno_model.eval()\n",
    "    \n",
    "    cnn_errors, fno_errors = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            state = batch['state'].to(device)\n",
    "            derived = batch['derived'].to(device)\n",
    "            \n",
    "            cnn_errors.append(torch.abs(cnn_model(state) - derived).cpu().numpy())\n",
    "            fno_errors.append(torch.abs(fno_model(state) - derived).cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(cnn_errors), np.concatenate(fno_errors)\n",
    "\n",
    "# Uncomment after training both models:\n",
    "# from fno_output_learning import DerivedQuantityModel  # or recreate the FNO model here\n",
    "# fno_output_model = ...\n",
    "# load_model(fno_output_model, 'derived_fno')\n",
    "# \n",
    "# cnn_err, fno_err = compare_models(conv_output_model, fno_output_model, test_loader, device)\n",
    "# print(\"Model Comparison (on ground truth):\")\n",
    "# print(f\"CNN - gamma_n MAE: {cnn_err[:, 0].mean():.6f}, gamma_c: {cnn_err[:, 1].mean():.6f}\")\n",
    "# print(f\"FNO - gamma_n MAE: {fno_err[:, 0].mean():.6f}, gamma_c: {fno_err[:, 1].mean():.6f}\")\n",
    "\n",
    "print(\"Model comparison ready - uncomment after training both notebooks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
